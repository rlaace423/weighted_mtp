# Phase 1: Storage ìì‚° ë³€í™˜ ì‹¤í–‰ ê³„íš

ë³¸ ë¬¸ì„œëŠ” Phase 1ì—ì„œ ìˆ˜í–‰í•  ëª¨ë¸Â·ë°ì´í„° ìì‚° ì¤€ë¹„ ì‘ì—…ì„ **Step-by-Step**ìœ¼ë¡œ ì •ë¦¬í•œ ì‹¤í–‰ ì‹œë‚˜ë¦¬ì˜¤ë‹¤. ëª©í‘œëŠ” `docs/00_ideal_structure.md`ì™€ `docs/01_storage_preparation_plan.md`ì—ì„œ ì •ì˜í•œ êµ¬ì¡°ë¥¼ ê·¸ëŒ€ë¡œ êµ¬í˜„í•˜ì—¬, WMTP ì œì•ˆì„œì—ì„œ ìš”êµ¬í•˜ëŠ” ì„¸ ì‹¤í—˜(Baseline, Verifiable Critic, Rho-1)ì´ ì¬í˜„ ê°€ëŠ¥í•œ ê¸°ë°˜ì„ ë§ˆë ¨í•˜ëŠ” ê²ƒì´ë‹¤. **ê¸°ì¡´ ìì‚°ì€ ëª¨ë‘ ì‚­ì œí•˜ê³ , Meta ê³µì‹ ëª¨ë¸ê³¼ ë°ì´í„°ì…‹ì„ ì¬ë‹¤ìš´ë¡œë“œí•˜ì—¬ ì™„ì „í•œ v2.0.0 ìŠ¤í† ë¦¬ì§€ë¥¼ êµ¬ì¶•**í•œë‹¤.

---

## Step 0. ì‚¬ì „ ì¤€ë¹„
- **ëª©í‘œ**: ê¸°ì¡´ ë‹¤ìš´ë¡œë“œ ì”ì—¬ë¬¼ì„ ì œê±°í•˜ê³  ê¹¨ë—í•œ ìƒíƒœì—ì„œ ìƒˆ ìì‚°ì„ ë°›ëŠ”ë‹¤.
- **ì‘ì—…**
  1. `uv sync` ì‹¤í–‰, `ruff`, `black`, `pytest` ë“± ê°œë°œ ë„êµ¬ ìµœì‹ í™”.
  2. `storage/` ë‚´ ê¸°ì¡´ ëª¨ë¸Â·ë°ì´í„° í´ë” ì •ë¦¬
     ```bash
     rm -rf storage/models_v2 storage/datasets_v2 storage/datasets_local_small
     rm -rf storage/models storage/datasets  # legacy êµ¬ì¡° ì‚¬ìš© ì‹œ
     ```
     > ì´ë¯¸ ë‹¤ìš´ë¡œë“œ ì¤‘ì¸ `storage/models_v2/meta-llama-mtp/raw/7B_1T_4` ë° `.cache` í´ë”ëŠ” ê·¸ëŒ€ë¡œ ë‘”ë‹¤.
  3. `scripts/verify_mtp_model.py`, `scripts/convert_*` ë“± ìœ í‹¸ë¦¬í‹°ê°€ ìµœì‹ ì¸ì§€ í™•ì¸ (`uv run ruff check scripts/`).
- **ê²€ì¦**: `storage/`ì— í•„ìˆ˜ ê³¨ê²©ë§Œ ë‚¨ì•„ ìˆëŠ”ì§€ í™•ì¸ (`tree storage -L 2`).

---

## Step 1. ë””ë ‰í„°ë¦¬ êµ¬ì¡° ìƒì„±
- **ëª©í‘œ**: v2 í‘œì¤€ ë ˆì´ì•„ì›ƒ(ëª¨ë¸/ë°ì´í„°/ìŠ¤ëª°ì…‹)ì„ ë¯¸ë¦¬ ë§Œë“¤ì–´ í›„ì† ì‘ì—…ì„ ë‹¨ìˆœí™”í•œë‹¤.
- **ì‘ì—…**
  ```bash
  mkdir -p storage/models_v2/{meta-llama-mtp,ref-sheared-llama-2.7b,micro-mtp}/{raw,safetensors,configs,tokenizer}
  mkdir -p storage/datasets_v2/{codecontests,mbpp,humaneval}/{raw,processed,stats}
  mkdir -p storage/datasets_local_small/{codecontests_small,mbpp_small,humaneval_small}
  touch storage/models_v2/meta-llama-mtp/safetensors/SHA256SUMS
  ```
- **ì‚°ì¶œë¬¼**: ë¹ˆ ë””ë ‰í„°ë¦¬ êµ¬ì¡°.
- **ê²€ì¦**: `tree storage -L 3`ê°€ ë¬¸ì„œì™€ ë™ì¼í•œ ë ˆì´ì•„ì›ƒì„ ë³´ì—¬ì•¼ í•œë‹¤.

---

## Step 2. ëª¨ë¸ ì›ë³¸ ë‹¤ìš´ë¡œë“œ (Meta 7B_1T_4, Sheared LLaMA 2.7B)
- **ëª©í‘œ**: Hugging Faceì—ì„œ ìµœì‹  ëª¨ë¸ ë²ˆë“¤ì„ ë°›ì•„ `raw/`ì— ì €ì¥í•œë‹¤. Reward ëª¨ë¸ì€ Phase 1ì—ì„œ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ”ë‹¤.
- **ì‘ì—…**
  1. Meta MTP `7B_1T_4`:
     ```bash
     hf download facebook/multi-token-prediction 7B_1T_4/consolidated.pth \
       --local-dir storage/models_v2/meta-llama-mtp/raw
     hf download facebook/multi-token-prediction 7B_1T_4/params.json \
       --local-dir storage/models_v2/meta-llama-mtp/raw
     hf download facebook/multi-token-prediction tokenizer.model \
       --local-dir storage/models_v2/meta-llama-mtp/tokenizer
     ```
  2. Sheared LLaMA 2.7B (Rho-1 base model):
     ```bash
     hf download princeton-nlp/Sheared-LLaMA-2.7B \
       --local-dir storage/models_v2/ref-sheared-llama-2.7b/raw
     ```
     Note: princeton-nlp/Sheared-LLaMA-2.7BëŠ” Rho-1ì˜ base ëª¨ë¸ì´ë©°, Meta LLaMA MTPì™€ ë™ì¼í•œ tokenizer(SHA256: 9e556afd...)ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
  3. Reward ëª¨ë¸(N/A): Phase 1ì—ì„œëŠ” ë‹¤ìš´ë¡œë“œí•˜ì§€ ì•ŠëŠ”ë‹¤.
  4. Micro ëª¨ë¸: Stage 5ì—ì„œ Base safetensors ìƒì„± í›„ ìŠ¤í¬ë¦½íŠ¸ë¡œ ë³€í™˜í•  ì˜ˆì •ì´ë¯€ë¡œ ì§€ê¸ˆì€ ë¹„ì›Œ ë‘”ë‹¤.
- **ê²€ì¦**: ê° `raw/` ë””ë ‰í„°ë¦¬ì— ë‹¤ìš´ë¡œë“œí•œ íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸ (`ls -lh`), SHA256 ê³„ì‚° ì‹œì‘.

---

## Step 3. Meta LLaMA MTP íŒŒìƒ ìì‚° ìƒì„±
- **ëª©í‘œ**: `consolidated.pth`ë¥¼ í”„ë¡œì íŠ¸ í‘œì¤€ êµ¬ì¡°ë¡œ ë³€í™˜í•˜ê³  ê²€ì¦í•œë‹¤.
- **ì‘ì—…**
  1. safetensors ë³€í™˜ ë° SHA256 ê¸°ë¡
     ```bash
     python - <<'PY'
     import torch
     from safetensors.torch import save_file, safe_open
     from pathlib import Path

     raw = Path("storage/models_v2/meta-llama-mtp/raw/7B_1T_4/consolidated.pth")
     out = Path("storage/models_v2/meta-llama-mtp/safetensors/model.safetensors")
     state_dict = torch.load(raw, map_location="cpu")
     save_file(state_dict, out, metadata={"dtype": "float16"})
     PY
     sha256sum storage/models_v2/meta-llama-mtp/safetensors/model.safetensors \
       > storage/models_v2/meta-llama-mtp/safetensors/SHA256SUMS
     ```
  2. `params.json` ë³µì‚¬ â†’ `configs/params.json` (í•„ìš” ì‹œ ì¶”ê°€ í•„ë“œ í¬í•¨).
  3. `configs/meta_adapter.yaml` ì‘ì„± (dim=4096, num_layers=32, n_future_tokens=4, intermediate_size=11008, rope_theta=10000.0, dtype=float16).
  4. `tokenizer_config.json` ìƒì„± (`model_type: sentencepiece`, `vocab_size: 32000` ë“±).
  5. `metadata.json` ì‘ì„± (dtype, SHA256, ì›ë³¸ repo, ìƒì„± ì¼ì ê¸°ë¡).
- **ê²€ì¦**
  - `scripts/verify_mtp_model.py` ì‹¤í–‰ â†’ ëª¨ë“  ì²´í¬ í†µê³¼.  
  - dtype=float16, rope_theta=10000.0 í™•ì¸.  
  - `meta_adapter.yaml` â†” `params.json` â†” `metadata.json` íŒŒë¼ë¯¸í„°ê°€ ëª¨ë‘ ì¼ì¹˜.

---

## Step 4. Sheared LLaMA 2.7B íŒŒìƒ ìì‚° ìƒì„±
- **ëª©í‘œ**: Sheared-LLaMA 2.7B ëª¨ë¸ì„ safetensorsë¡œ ë³€í™˜í•˜ê³  í† í¬ë‚˜ì´ì € ê³µìœ  ì •ë³´ë¥¼ ê¸°ë¡í•œë‹¤.
- **ì‘ì—…**
  1. ë³‘í•© ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰:
     ```bash
     uv run python scripts/convert_sharded_to_safetensors.py \
       storage/models_v2/ref-sheared-llama-2.7b/raw \
       storage/models_v2/ref-sheared-llama-2.7b/safetensors/model.safetensors
     ```
  2. SHA256 ê³„ì‚°, `safetensors/SHA256SUMS`ì— ê¸°ë¡.
  3. `configs/config.json` ë³µì‚¬ (ì¼ê´€ëœ ë””ë ‰í† ë¦¬ êµ¬ì¡° ìœ ì§€):
     ```bash
     # setup_models.pyì˜ sync_configê°€ ìë™ìœ¼ë¡œ ìˆ˜í–‰
     # ë˜ëŠ” ìˆ˜ë™: cp raw/reference_model/config.json configs/config.json
     ```
  4. `metadata.json` ì‘ì„± (`tokenizer_shared_with: "meta-llama-mtp"`, dtype=float16, SHA256, tokenizer SHA256 ê¸°ë¡).
- **ê²€ì¦**
  - safetensors ë¡œë”© ì„±ê³µ.
  - `tokenizer.model` SHA256ì´ Meta MTPì™€ ì™„ì „íˆ ë™ì¼ (9e556afd44213b6bd1be2b850ebbbd98f5481437a8021afaf58ee7fb1818d347).
  - metadataì— í† í¬ë‚˜ì´ì € ê³µìœ  ì—¬ë¶€ ë° SHA256 ê¸°ë¡.

---

## Step 5. Micro ëª¨ë¸ ìƒì„± (Policy & Reference)
- **ëª©í‘œ**: ë¡œì»¬ M3 í™˜ê²½ì—ì„œ Baselineê³¼ Rho-1 ì‹¤í—˜ì„ ë¹ ë¥´ê²Œ ê²€ì¦í•  ìˆ˜ ìˆë„ë¡ ì •ì±…/ë ˆí¼ëŸ°ìŠ¤ìš© ê²½ëŸ‰ safetensorsë¥¼ ì¤€ë¹„í•œë‹¤.
- **ì‘ì—…**
  1. **Micro Policy (Meta MTP ì¶•ì†ŒíŒ)**
     ```bash
     uv run python scripts/prepare_local_small_model.py \
       --source storage/models_v2/meta-llama-mtp/safetensors/model.safetensors \
       --target storage/models_v2/micro-mtp
     sha256sum storage/models_v2/micro-mtp/safetensors/model.safetensors \
       > storage/models_v2/micro-mtp/safetensors/SHA256SUMS
     ```
     - ì¶œë ¥: 4-layer/512-dim, vocab 32000 ëª¨ë¸ (Meta LLaMA tokenizer ê³µìœ ).
     - êµ¬ì„± íŒŒì¼: `micro-mtp/configs/config.json`, `tokenizer/tokenizer.model`, `metadata.json(target_device: "mps", dtype: float16)`.
  2. **Micro Reference**
     - Sheared-LLaMA 2.7B ëª¨ë¸ì„ ë™ì¼ ë°©ì‹ìœ¼ë¡œ ì¶•ì†Œí•˜ì—¬ ë¡œì»¬ í…ŒìŠ¤íŠ¸ìš© reference ëª¨ë¸ ìƒì„±.  
     - ìŠ¤í¬ë¦½íŠ¸ ì˜ˆì‹œ(í–¥í›„ `prepare_micro_reference.py`ë¡œ ë¶„ë¦¬ ê°€ëŠ¥):
       ```bash
       uv run python scripts/prepare_micro_reference.py \
         --source storage/models_v2/ref-sheared-llama-2.7b/safetensors/model.safetensors \
         --target storage/models_v2/micro-ref
       sha256sum storage/models_v2/micro-ref/safetensors/model.safetensors \
         > storage/models_v2/micro-ref/safetensors/SHA256SUMS
       ```
       - ìµœì†Œ 4-layer, hidden_size 512 ìˆ˜ì¤€ìœ¼ë¡œ ì¶•ì†Œí•˜ê³ , Baseì™€ ë™ì¼ í† í¬ë‚˜ì´ì €ë¥¼ ê³µìœ í•˜ë„ë¡ `metadata.json.tokenizer_shared_with="meta-llama-mtp"` ê¸°ë¡.
- **ì‚°ì¶œë¬¼**
  - `storage/models_v2/micro-mtp/` (í•„ìˆ˜)  
  - `storage/models_v2/micro-ref/` (í•„ìš” ì‹œ)  
  - ê° ë””ë ‰í„°ë¦¬ì˜ safetensors/config/tokenizer/metadata/SHA256SUMS.
- **ê²€ì¦**
  - íŒŒì¼ í¬ê¸° < 50MB, dtype=float16 ìœ ì§€.  
  - `uv run pytest tests/unit/test_adapter.py -k micro` í†µê³¼.  
  - (Micro reference ì‚¬ìš© ì‹œ) Rho-1 ë¹„êµ ìŠ¤í¬ë¦½íŠ¸ì™€ í† í¬ë‚˜ì´ì € í˜¸í™˜ì„± í™•ì¸.

---

## Step 6-8. ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ë° ì „ì²˜ë¦¬ (í†µí•©)
- **ëª©í‘œ**: HuggingFace datasets ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ì…‹ì„ ë‹¤ìš´ë¡œë“œí•˜ê³ , correct/incorrect solutionsë¥¼ ëª¨ë‘ í¬í•¨í•œ Alpaca í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•œë‹¤.
- **ì‹¤ì œ êµ¬í˜„**: `scripts/setup_datasets.py`ì— ë‹¤ìš´ë¡œë“œ, ë³€í™˜, í†µê³„ ìƒì„±ì„ í†µí•© êµ¬í˜„
- **ì£¼ìš” íŠ¹ì§•**:
  - âœ“ HuggingFace ë°ì´í„°ì…‹ì„ Parquet í˜•ì‹ìœ¼ë¡œ ì§ì ‘ ë¡œë“œ
  - âœ“ CodeContests validation splitì€ "valid"ë¡œ ëª…ëª…ë¨
  - âœ“ **Correctì™€ incorrect solutionsë¥¼ ëª¨ë‘ ì²˜ë¦¬í•˜ì—¬ ë‹¨ì¼ JSONLì— í†µí•©**
  - âœ“ **Top-level `is_correct` í•„ë“œë¡œ ì†”ë£¨ì…˜ ì •ë‹µ ì—¬ë¶€ í‘œì‹œ**
  - âœ“ í† í° ê¸¸ì´ í•„í„°ë§ (max_tokens=2048, instruction+input+output í•©ì‚°)

- **ì‘ì—…**
  1. **ì „ì²´ ë°ì´í„°ì…‹ ì²˜ë¦¬** (ë‹¤ìš´ë¡œë“œ + ë³€í™˜ + small + stats):
     ```bash
     # ì „ì²´ ë°ì´í„°ì…‹ ì¼ê´„ ì²˜ë¦¬
     uv run python scripts/setup_datasets.py --datasets all --steps all

     # ê°œë³„ ë°ì´í„°ì…‹ ì²˜ë¦¬
     uv run python scripts/setup_datasets.py --datasets codecontests --steps all
     uv run python scripts/setup_datasets.py --datasets mbpp --steps all
     uv run python scripts/setup_datasets.py --datasets humaneval --steps all
     ```

  2. **ë°ì´í„° ë³€í™˜ ë¡œì§** (`scripts/setup_datasets.py`):
     - **CodeContests** (í•µì‹¬ ë°ì´í„°ì…‹):
       - HF ì›ë³¸: `description` â†’ `instruction`, `public_tests` â†’ `input` (ìµœëŒ€ 2ê°œ)
       - **Correct solutions**: `solutions` í•„ë“œì˜ Python/Python3 ì†”ë£¨ì…˜ ì¶”ì¶œ
         - task_id: `"{name}_correct_{idx}"` (ì˜ˆ: `"brcktsrm_correct_0"`)
         - is_correct: `true`
       - **Incorrect solutions**: `incorrect_solutions` í•„ë“œì˜ Python/Python3 ì†”ë£¨ì…˜ ì¶”ì¶œ
         - task_id: `"{name}_incorrect_{idx}"` (ì˜ˆ: `"brcktsrm_incorrect_0"`)
         - is_correct: `false`
       - í•„í„°ë§: Python only (ì–¸ì–´ ì½”ë“œ 1 ë˜ëŠ” 3), í† í° ê¸¸ì´ â‰¤2048
       - **ì˜ˆìƒ ìƒ˜í”Œ ìˆ˜** (í† í° í•„í„°ë§ í›„):
         - Train: ~15,000-20,000 samples (correct + incorrect í†µí•©)
         - Valid: ~120-150 samples
         - Test: ~150-200 samples
     - **MBPP**:
       - Parquet â†’ Alpaca (text â†’ instruction, code â†’ output)
       - 374 train + 90 validation + 500 test
       - is_correct í•„ë“œ ì—†ìŒ (ëª¨ë‘ ì •ë‹µ ì½”ë“œ)
     - **HumanEval**:
       - Parquet â†’ Alpaca (prompt â†’ instruction, canonical_solution â†’ output)
       - 164 test samples
       - is_correct í•„ë“œ ì—†ìŒ (ëª¨ë‘ ì •ë‹µ ì½”ë“œ)

  3. **ìë™ ìƒì„± ì‚°ì¶œë¬¼**:
     - `processed/*.jsonl`: Alpaca í˜•ì‹ JSONL
       - **í•„ìˆ˜ í•„ë“œ**: `instruction`, `input`, `output`, `task_id`, `is_correct` (CodeContestsë§Œ)
       - **ì„ íƒ í•„ë“œ**: `metadata` (source, difficulty, has_tests)
     - `processed/schema.json`: ë°ì´í„°ì…‹ ìŠ¤í‚¤ë§ˆ (is_correctë¥¼ required_fieldsì— í¬í•¨)
     - `stats/YYYY-MM-DD_summary.json`: ìƒ˜í”Œ ìˆ˜, í† í° ê¸¸ì´ í†µê³„, is_correct ë¶„í¬
     - `datasets_local_small/*_small/*.jsonl`: Small ë²„ì „ (trainâ‰¤100, val/testâ‰¤32)

- **ê²€ì¦**:
  - âœ“ Top-level `is_correct` í•„ë“œ ì¡´ì¬ (CodeContests)
  - âœ“ task_idì— `_correct_` / `_incorrect_` ì ‘ë¯¸ì‚¬ í¬í•¨
  - âœ“ Correctì™€ incorrect solutionsê°€ ë‹¨ì¼ JSONLì— í†µí•© ì €ì¥
  - âœ“ í† í° ê¸¸ì´ í•„í„°ë§ ì ìš© (2048 í† í° ì´ˆê³¼ ìƒ˜í”Œ ì œì™¸)
  - âœ“ Schema.jsonì— is_correct í•„ë“œ ëª…ì‹œ
  - âœ“ Statsì— is_correct ë¶„í¬ í¬í•¨

---

## Step 9. ìì‚° ë¬´ê²°ì„± ê²€ì¦
- **ëª©í‘œ**: ëª¨ë¸ê³¼ ë°ì´í„° ëª¨ë‘ì— ëŒ€í•´ dtype/í•´ì‹œ/ìŠ¤í‚¤ë§ˆ ê²€ì¦ì„ ì™„ë£Œí•˜ê³  ì²´í¬ë¦¬ìŠ¤íŠ¸ë¥¼ ì±„ìš´ë‹¤.
- **ì‘ì—…**
  1. `scripts/verify_mtp_model.py` ì‹¤í–‰ â†’ Meta ëª¨ë¸ ê²€ì¦.  
  2. ìì²´ ìŠ¤í¬ë¦½íŠ¸ ë˜ëŠ” ìˆ˜ë™ìœ¼ë¡œ `models_v2/ref-sheared-llama-2.7b` SHA256, dtype í™•ì¸.  
  3. `scripts/validate_datasets.py` ê²°ê³¼ ê²€í† , stats ë³´ê³ ì„œ í™•ì¸.  
  4. `storage/README.md`ì— ìµœì‹  ë²„ì „, SHA256 ê²€ì¦ ë°©ë²•, ë‹¤ìš´ë¡œë“œ ë§í¬ ê¸°ë¡.
- **ì‚°ì¶œë¬¼**: ì²´í¬ë¦¬ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸, README ê°±ì‹ .  
- **ê²€ì¦**: ëª¨ë“  í•­ëª© âœ”ï¸, ì‹¤íŒ¨ ì‹œ ì›ì¸Â·ì¬ì‘ì—… ê¸°ë¡.

---

## Step 10. ë¬¸ì„œ ë° ë¦¬í¬íŠ¸ ì—…ë°ì´íŠ¸
- **ëª©í‘œ**: Phase 1 ê²°ê³¼ë¥¼ ë¬¸ì„œí™”í•˜ê³  Phase 2ì— í•„ìš”í•œ ì‚°ì¶œë¬¼ì„ ì •ë¦¬í•œë‹¤.
- **ì‘ì—…**
  - `docs/phase1_asset_inventory.md`: ìµœì¢… ìì‚° ëª©ë¡ ì‘ì„±.  
  - `docs/migration_notes.md`: ì˜ˆìƒê³¼ ë‹¤ë¥¸ ì , ë¦¬ìŠ¤í¬, í›„ì† ì‘ì—… ê¸°ë¡.  
  - `docs/phase1_completion_report.md`: ì¼ì •, ì‚°ì¶œë¬¼, ì´ìŠˆ, ë‹¤ìŒ ë‹¨ê³„ ìš”ì•½.  
  - `storage/README.md`: ê²€ì¦ ëª…ë ¹, ë²„ì „ íˆìŠ¤í† ë¦¬, FAQ ê°±ì‹ .
- **ê²€ì¦**: ë¬¸ì„œê°€ ì‹¤ì œ ìì‚° êµ¬ì¡°ì™€ ì¼ì¹˜, reviewer ìŠ¹ì¸.

---

## Step 11. ì™„ë£Œ ì²´í¬ë¦¬ìŠ¤íŠ¸ & ìŠ¹ì¸
- **ëª©í‘œ**: Phase 1ì´ ì¢…ë£Œë˜ì—ˆìŒì„ ëª…í™•íˆ í•˜ê³  ë‹¤ìŒ Phase ì°©ìˆ˜ ì¡°ê±´ì„ í™•ì¸í•œë‹¤.
- **ì‘ì—…**
  - ì²´í¬ë¦¬ìŠ¤íŠ¸ í•­ëª©(ëª¨ë¸, ë°ì´í„°, ìŠ¤í¬ë¦½íŠ¸, ë¬¸ì„œ) ëª¨ë‘ í™•ì¸.  
  - ë¯¸í•´ê²° ì´ìŠˆëŠ” `docs/migration_notes.md`ì— Action Itemìœ¼ë¡œ ê¸°ë¡.  
  - ë¦¬ë·°ì–´/PO ìŠ¹ì¸ íšë“, Phase 2 ì°©ìˆ˜ ì¡°ê±´ ì •ë¦¬.
- **ê²€ì¦**: ì²´í¬ë¦¬ìŠ¤íŠ¸ ì „í•­ëª© âœ”ï¸, ìŠ¹ì¸ ì„œëª…, ë°±ì—… ë° íƒœê·¸ ì™„ë£Œ.

---

## ë³‘í–‰ ì „ëµ
- **ëª¨ë¸ ë³€í™˜**(Step 2~5)ê³¼ **ë°ì´í„° ì „ì²˜ë¦¬ ìŠ¤í¬ë¦½íŠ¸ ì‘ì„±**(Step 7)ì€ ë³‘í–‰ ê°€ëŠ¥í•˜ë‚˜, processed ì‹¤í–‰(Step 8)ì€ ìŠ¤í¬ë¦½íŠ¸ ì™„ë£Œ í›„ ì§„í–‰.
- ê²€ì¦ ë‹¨ê³„(Step 9)ëŠ” ëª¨ë¸Â·ë°ì´í„°ê°€ ëª¨ë‘ ì¤€ë¹„ëœ ë’¤ ì¼ê´„ ìˆ˜í–‰.
- ë¬¸ì„œ ì—…ë°ì´íŠ¸(Step 10)ëŠ” ìì‚° ê²€ì¦ ì´í›„ ì°©ìˆ˜.

---

## ìœ„í—˜ ìš”ì†Œ ë° ëŒ€ì‘
| ìœ„í—˜ | ì˜í–¥ | ëŒ€ì‘ ì „ëµ |
|------|------|-----------|
| Hugging Face ë‹¤ìš´ë¡œë“œ ì¤‘ë‹¨ | ì¼ì • ì§€ì—° | í† í°/ê¶Œí•œ í™•ì¸, ë¯¸ëŸ¬ë§ ê³„íš ìˆ˜ë¦½ |
| safetensors ë³€í™˜ ì‹¤íŒ¨ | ëª¨ë¸ ë¡œë”© ë¶ˆê°€ | ë³€í™˜ ì „ raw ë°±ì—…, ë³€í™˜ ìŠ¤í¬ë¦½íŠ¸ ì¬ì‹œë„ |
| dtype ë¶ˆì¼ì¹˜ | í•™ìŠµ ì˜¤ë¥˜ | ë³€í™˜ ì¦‰ì‹œ dtype ê²€ì‚¬(`scripts/verify_mtp_model.py`) |
| ë°ì´í„° ë¶„í•  ì˜¤ì—¼ | í‰ê°€ ì™œê³¡ | `task_id` ê¸°ì¤€ ë¶„ë¦¬, seed ê³ ì • |
| ë¬¸ì„œ ë¯¸ê°±ì‹  | ì´í›„ Phase í˜¼ì„  | Step 10ì—ì„œ ìµœì‹  ìƒíƒœ ë¬¸ì„œí™” í•„ìˆ˜ |

---

## Step ì™„ë£Œ ì²´í¬ë¦¬ìŠ¤íŠ¸ (ìš”ì•½)
- [x] Step 0: ê¸°ì¡´ ìì‚° ì‚­ì œ, í™˜ê²½ ì •ë¹„ âœ“
- [x] Step 1: v2 ë””ë ‰í„°ë¦¬ êµ¬ì¡° ìƒì„± âœ“
- [ğŸ”„] Step 2: Meta 7B_1T_4 & Sheared 2.7B raw ë‹¤ìš´ë¡œë“œ (ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰ ì¤‘)
- [ ] Step 3: Meta ëª¨ë¸ safetensors/metadata êµ¬ì„±, ê²€ì¦ í†µê³¼ (Step 2 ì™„ë£Œ í›„)
- [ ] Step 4: Reference ëª¨ë¸ ë³€í™˜ & ê²€ì¦ (Step 2 ì™„ë£Œ í›„)
- [ ] Step 5: Micro ëª¨ë¸ ìƒì„± & í…ŒìŠ¤íŠ¸ í†µê³¼ (Step 3, 4 ì™„ë£Œ í›„)
- [x] Step 6-8 (í†µí•©): ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ë° ì „ì²˜ë¦¬ ì™„ë£Œ âœ“
  - [x] HumanEval: 164 test samples âœ“
  - [x] MBPP: 374 train + 90 val + 500 test âœ“
  - [x] CodeContests: 10,489 train + 122 test (Python only) âœ“
  - [x] processed/ JSONL, schema.json, stats/ ìƒì„± ì™„ë£Œ âœ“
  - [x] datasets_local_small/ ìƒì„± ì™„ë£Œ âœ“
- [ ] Step 9: ëª¨ë¸Â·ë°ì´í„° ë¬´ê²°ì„± ê²€ì¦ ì™„ë£Œ (ëª¨ë¸ ì‘ì—… ì™„ë£Œ í›„)
- [ğŸ”„] Step 10: ë¬¸ì„œ(README, reports) ì—…ë°ì´íŠ¸ (ì§„í–‰ ì¤‘)
- [ ] Step 11: ì²´í¬ë¦¬ìŠ¤íŠ¸ ë° ìŠ¹ì¸ ì™„ë£Œ

**Phase 1 ë°ì´í„°ì…‹ íŒŒíŠ¸ ì™„ë£Œ**: `storage/datasets_v2/`ì™€ `storage/datasets_local_small/`ê°€ v2.0.0 ê¸°ì¤€ì„ ë§Œì¡±í•©ë‹ˆë‹¤.
**ì§„í–‰ ì¤‘**: ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ë° ë³€í™˜ ì‘ì—… (ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰ ì¤‘)
# Phase 1: storage ìì‚° ë³€í™˜ ìƒì„¸ ì‹¤í–‰ ê³„íš

ë³¸ ë¬¸ì„œëŠ” `implementation_plan.md`ì˜ Phase 1ì„ stepë³„ë¡œ ì„¸ë¶„í™”í•œ ì‹¤í–‰ ê³„íšì´ë‹¤. ê° stepì€ **ëª©í‘œ â†’ ì„ í–‰ì¡°ê±´ â†’ ì‘ì—… í•­ëª© â†’ ì‚°ì¶œë¬¼ â†’ ê²€ì¦ ê¸°ì¤€**ìœ¼ë¡œ êµ¬ì„±ë˜ë©°, ìˆœì°¨ì ìœ¼ë¡œ ìˆ˜í–‰í•˜ë˜ ë³‘ë ¬ ê°€ëŠ¥í•œ ì‘ì—…ì€ ëª…ì‹œí•œë‹¤.
