{'n_epochs': 2.0, 'batch_size': 16, 'gradient_accumulation_steps': 2, 'trunk_learning_rate': 1e-05, 'value_head_learning_rate': 5e-05, 'max_grad_norm': 1.0, 'beta': 0.9, 'weight_clip_min': 0.1, 'weight_clip_max': 3, 'loss_type': 'mse', 'gamma': 1.0, 'lam': 1.0, 'aux_coef': 0.3, 'log_interval': 1, 'lr_scheduler': {'type': 'cosine', 'warmup_ratio': 0.1, 'min_lr_ratio': 0.005}}