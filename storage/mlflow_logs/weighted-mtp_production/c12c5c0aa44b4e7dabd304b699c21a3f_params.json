{
  "logging": "{'level': 'INFO', 'format': '%(asctime)s [%(levelname)s] [%(name)s] %(message)s'}",
  "system_cpu_count": "48",
  "system_ram_total_gb": "2015.35",
  "project": "{'name': 'weighted-mtp', 'version': '2.0.0'}",
  "experiment": "{'name': 'baseline-mtp', 'description': 'Baseline MTP with uniform weights (all tokens weight=1.0)', 'stage': 'baseline', 'tags': ['baseline', 'uniform-weight', 'production']}",
  "models": "{'policy': {'name': 'meta-llama-mtp', 'path': 'storage/models/meta-llama-mtp', 'tokenizer_path': 'storage/models/meta-llama-mtp/tokenizer', 'params': {'dim': 4096, 'n_layers': 32, 'n_heads': 32, 'n_future_tokens': 4, 'intermediate_size': 11008, 'rope_theta': 10000.0, 'vocab_size': 32000}, 'dtype': 'bfloat16'}}",
  "dataset": "{'name': 'codecontests', 'train': 'storage/datasets/codecontests/processed/train.jsonl', 'validation': 'storage/datasets/codecontests/processed/valid.jsonl', 'max_length': 2048}",
  "data_sampling": "{'n_samples': 130000, 'auto_data_balancing': False, 'correct_ratio': 1.0, 'difficulty_bins': {'all': [1, 25]}, 'curriculum_schedule': [{'epoch_range': [0.0, 3.0], 'difficulty_weights': {'all': 1.0}}], 'seed': 42}",
  "training": "{'n_epochs': 3.0, 'batch_size': 32, 'gradient_accumulation_steps': 1, 'learning_rate': 5e-05, 'max_grad_norm': 0.1, 'log_interval': 1, 'lr_scheduler': {'type': 'cosine', 'warmup_ratio': 0.03, 'min_lr_ratio': 0.005}}",
  "checkpoint": "{'save_dir': 'storage/checkpoints/baseline/baseline-mtp', 'save_checkpoint_every': 0.5, 'save_best': True, 'save_final': True, 'save_total_limit': 3, 's3_upload': False}",
  "runtime": "{'device': 'cuda', 'seed': 42, 'mixed_precision': True}",
  "distributed": "{'fsdp': {'sharding_strategy': 'FULL_SHARD', 'mixed_precision': True, 'cpu_offload': False, 'activation_checkpointing': True}}",
  "storage": "{'root': 'storage', 'models_dir': 'storage/models', 'datasets_dir': 'storage/datasets', 'checkpoints_dir': 'storage/checkpoints'}",
  "mlflow": "{'tracking_uri': 'http://13.50.240.176', 'experiment': 'weighted-mtp/production', 's3_artifacts': 's3://wmtp/mlflow-artifacts'}",
  "dataset_train_samples": "32500",
  "model_total_params": "6738415616",
  "model_trainable_params": "6738415616",
  "model_non_trainable_params": "0",
  "dataset_val_samples": "1625",
  "dataset_train_batches": "1016",
  "dataset_val_batches": "51"
}