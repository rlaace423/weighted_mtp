{
  "project": "{'name': 'weighted-mtp', 'version': '2.0.0'}",
  "experiment": "{'name': 'baseline-mtp', 'description': 'Baseline MTP with uniform weights (all tokens weight=1.0)', 'stage': 'baseline', 'tags': ['baseline', 'uniform-weight', 'production']}",
  "models": "{'policy': {'name': 'meta-llama-mtp', 'path': 'storage/models/meta-llama-mtp', 'tokenizer_path': 'storage/models/meta-llama-mtp/tokenizer', 'params': {'dim': 4096, 'n_layers': 32, 'n_heads': 32, 'n_future_tokens': 4, 'intermediate_size': 11008, 'rope_theta': 10000.0, 'vocab_size': 32000}, 'dtype': 'bfloat16'}}",
  "dataset": "{'name': 'codecontests', 'train': 'storage/datasets/codecontests/processed/train.jsonl', 'validation': 'storage/datasets/codecontests/processed/valid.jsonl', 'max_length': 2048}",
  "data_sampling": "{'n_samples': 150000, 'auto_data_balancing': False, 'correct_ratio': 1.0, 'curriculum_learning': True, 'difficulty_bins': {'easy': [6, 7], 'medium': [8, 10], 'hard': [11, 25]}, 'curriculum_schedule': [{'epoch_range': [0.0, 0.3], 'difficulty_weights': {'easy': 0.7, 'medium': 0.3, 'hard': 0.0}}, {'epoch_range': [0.3, 0.7], 'difficulty_weights': {'easy': 0.3, 'medium': 0.5, 'hard': 0.2}}, {'epoch_range': [0.7, 1.0], 'difficulty_weights': {'easy': 0.1, 'medium': 0.6, 'hard': 0.3}}], 'seed': 42}",
  "training": "{'n_epochs': 3.0, 'batch_size': 32, 'gradient_accumulation_steps': 2, 'learning_rate': 2e-05, 'max_grad_norm': 1.0, 'log_interval': 1, 'lr_scheduler': {'type': 'cosine', 'warmup_ratio': 0.05, 'min_lr_ratio': 0.0}}",
  "checkpoint": "{'save_dir': 'storage/checkpoints/baseline/baseline-mtp', 'save_checkpoint_every': 0.5, 'save_best': True, 'save_final': True, 'save_total_limit': 2, 's3_upload': False}",
  "runtime": "{'device': 'cuda', 'seed': 42, 'mixed_precision': True}",
  "distributed": "{'fsdp': {'sharding_strategy': 'FULL_SHARD', 'mixed_precision': True, 'cpu_offload': False, 'activation_checkpointing': True}}",
  "storage": "{'root': 'storage', 'models_dir': 'storage/models', 'datasets_dir': 'storage/datasets', 'checkpoints_dir': 'storage/checkpoints'}",
  "mlflow": "{'tracking_uri': 'http://13.50.240.176', 'experiment': 'weighted-mtp/production', 's3_artifacts': 's3://wmtp/mlflow-artifacts'}",
  "logging": "{'level': 'INFO', 'format': '%(asctime)s [%(levelname)s] [%(name)s] %(message)s'}",
  "dataset_train_samples": "37500",
  "dataset_val_samples": "1875",
  "dataset_train_batches": "1172",
  "dataset_val_batches": "59",
  "model_total_params": "6738415616",
  "model_trainable_params": "6738415616",
  "model_non_trainable_params": "0",
  "system_cpu_count": "48",
  "system_ram_total_gb": "2015.35"
}